<p>
Prosody plays a big role in both direct speech-to-speech translation and cascaded systems. In both the systems prosody modelling has to be done in order to deliver
semantically meaningful sentences in addition to expressing the same emotion in the source utterance. The problem becomes more difficult because prosody cannot be just 
mapped across langauges as different languages have different way of expressing the same emotion in addition to being context dependent. It has been highlighted in 
AMTA2022 where a keynote speaker presented an example from Squid Game (company <it>Translated</it>; tool <it>Matesub</it>), the synthesis sounded unnatural. 
</p>
<hr>
<h2>Proposed solution</h2>

<hr>
<h2>Previous work</h2>
<h3>Prosody modelling in TTS</h3>
<p>
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9414102'>Xu et.al</a> proposes the use of textual embeddings of neighbouring sentences to improve prosody
generation of utterances in a paragraph in E2E fashion without using any explicit prosody features. Cross-utterance context vectors produced by an additional cross-utterance
encoder based on sentence embeddings extracted from pretrained BERT model are used to augment the input to Tactotron2. They also found that prosody can be controlled by 
changing the neighbouring sentences. To show how changing the neighbouring sentences changes the pitch and duration of the tartget snetence, they compared the
  mel-spectrograms of the sentence <it>Tom called Mary</it> where 1) <it>Tom</it> was the keyword, 2) <it>called</it> was the keyword. There was a variation in pitch and
duration of the keywords in the 2 scenarios, indicating change in prosody.
</p>
<p>
In <a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9640518'>Du et.al</a>, they modelled phone-level prosodies with a GMM-based mixture density 
network(MDN) and then extend it for multi-speaker TTS using speaker adaptation transforms of Gaussian means and variances. They also show that they can clone the 
prosodies from a reference speech by sampling prosodies from the Gaussian components that produce the reference prosodies. Their experiments  show that the proposed 
method with GMM-based MDN not only achieves significantly better diversity than using a single Gaussian in both single-speaker and multispeaker TTS, but also provides 
better naturalness. The prosody cloning experiments demonstrate that the prosody similarity of the proposed method with GMM-based MDN is comparable to recent
proposed fine-grained VAE while the target speaker similarity is better. 
<br>
They used MCD as a measure to find out the distance between ground-truth phone-level prososdies and utterance-level prosodies. As expected phone-level prosodies produced
lower MCD as phone-level prossody representation contain more information about phone pronounciation than utterance-leve prosody representation in both single-speaker 
and multi-speaker systems. It was discovered that PLP(phone-level prosody modelling)-GMM produced better prosody diversity than PLP-SG(single gaussian) because a 
sequence of phone-level embeddings depicts the prosody more precisely than an utterance-level embedding Gaussian mixtures can better model the phone-level prosody
embeddings than a single Gaussian. 
<br>
The MUSHRA score of PLP-GMM is 25.3% and 8.6% higher than PLP-SG on single-speaker and multi-speaker task respectively with p-value<0.05. It was found that global prosody
representation provided limited information on phone-level prosody and was too coarse to precisely control the synthesis. Phone-level prosodies were controlled using 
specified Gaussian indices.
</p>
<p>
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9414413'>Hodari et.al</a>
</p>
