<p>
Prosody plays a big role in both direct speech-to-speech translation and cascaded systems. In both the systems prosody modelling has to be done in order to deliver
semantically meaningful sentences in addition to expressing the same emotion in the source utterance. The problem becomes more difficult because prosody cannot be just 
mapped across langauges as different languages have different way of expressing the same emotion in addition to being context dependent. It has been highlighted in 
AMTA2022 where a keynote speaker presented an example from Squid Game (company <it>Translated</it>; tool <it>Matesub</it>), the synthesis sounded unnatural. 
</p>
<hr>
<h3>Proposed solution</h3>

<hr>
<h2>Previous work</h2>
<h3>Prosody modelling in TTS</h3>
<p>
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9414102'>Xu et.al</a> proposes the use of textual embeddings of neighbouring sentences to improve prosody
generation of utterances in a paragraph in E2E fashion without using any explicit prosody features. Cross-utterance context vectors produced by an additional cross-utterance
encoder based on sentence embeddings extracted from pretrained BERT model are used to augment the input to Tactotron2. They also found that prosody can be controlled by 
changing the neighbouring sentences. To show how changing the neighbouring sentences changes the pitch and duration of the tartget snetence, they compared the
  mel-spectrograms of the sentence <it>Tom called Mary</it> where 1) <it>Tom</it> was the keyword, 2) <it>called</it> was the keyword. There was a variation in pitch and
duration of the keywords in the 2 scenarios, indicating change in prosody.
</p>
<p>
In <a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9640518'>Du et.al</a>, they modelled phone-level prosodies with a GMM-based mixture density 
network(MDN) and then extend it for multi-speaker TTS using speaker adaptation transforms of Gaussian means and variances. They also show that they can clone the 
prosodies from a reference speech by sampling prosodies from the Gaussian components that produce the reference prosodies. Their experiments  show that the proposed 
method with GMM-based MDN not only achieves significantly better diversity than using a single Gaussian in both single-speaker and multispeaker TTS, but also provides 
better naturalness. The prosody cloning experiments demonstrate that the prosody similarity of the proposed method with GMM-based MDN is comparable to recent
proposed fine-grained VAE while the target speaker similarity is better. 
  
</p>
