I haven't seen the issue of speaker similarity being addressed in speech translation yet. Although most of the samples from recent works show there is a stark difference
in source and target speaker. 

<p>
If I had to solve it I would take a parallel speaker encoder to encode speaker characteristics like speaker ID, speaking rate. I would not try to encode prosody because 
prosody cannot be mapped across languages. It is extremely difficult to encode only some of the characteristics of a speaker and silence the others. In this case, I only 
want information on gender, speaking rate to be marked as speaker identity. I amnot interested in information like their accent, flow, prosody of the utterances.
I would try to extract speaker x-vectors and and perform a clustering to determine which dimensions represent the wanted and unwanted information and use weights to amplify
to obtain the information I need. The modified x-vector representation can then be used to learn a latent space to enocde the speaker information needed.
</p>
