<!DOCTYPE html>
<html>
  <body>
<p> 
This is an important factor in speaker characteristics that need to incorporated in speech translations. It influneces the perceived prosody of the target synthesis and
in turn ifluences the naturalness a lot. 
</p>
 <hr>
<h2>Proposed solution</h2>
<p>
Since this is part of speaker characteristics, I think my approach in learning speaker characteristics using x-vectors should be able to solve the problem. This solution
will work only for direct speech-to-speech translation system.
</p>
<p>
For cascaded system, this has to modelled with prosody/controllable TTS with human-in-the-loop for better user experience. 
</p>  
<hr>
<h2>Previous work</h2> 
<p>
This work from Amazon AI by <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9747158">Effendi et.al</a> addresses the issue of <it>isochrony</it> because dubbed speech has to match
the timing an dpauses of the original audio and video. Their experimental results show that new models improve or match the performance of prosodic alignment and 
significantly enhance neural TTS speech quality for both slow and fast speaking rates.
</p>
<p>
<a href='https://arxiv.org/pdf/2001.06785.pdf'>Federico et.al </a>
</p>
<p>
<a href='https://www.isca-speech.org/archive_v0/Interspeech_2020/pdfs/2983.pdf>Federico et.al</a>
</p>
  </body>
</html>
